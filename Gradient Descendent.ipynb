{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is one of the most popular algorithms to perform optimization and by far the most common way to optimize neural networks\n",
    "\n",
    "Gradient descent is an optimization algorithm used to find the local minimum of a function. It is commonly used in many different machine learning algorithms.\n",
    "\n",
    "Minimizing a quadratic equation\n",
    "To start, let's suppose we have a simple quadratic function, f(x)=x2−6x+5f(x)=x2−6x+5, and we want to find the minimum of this function. There are plenty of possible reasons why you would want to find the minimum: For example, an object (like a hot air balloon) might be falling down a certain amount of time, before rising again. You want to find out the lowest height of the balloon to make sure you don't accidentally crash into the ground. We can solve this analytically using calculus, by finding the derivate and setting it to zero:\n",
    "\n",
    "f′(x)=2x−62x−6=02x=6x=3(1)(2)(3)(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimizing a quadratic function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= np.linspace(-10,10,1000) #we generated 1000 point between -10 and 10\n",
    "y = x**2 - 6*2 + 5  #f(x)=x2−6x+5\n",
    "\n",
    "fig, xa = plt.subplots()\n",
    "xa.plot(x,y)\n",
    "#fig.show()\n",
    "\n",
    "def function_derivate(x):\n",
    "    return 2*x -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minima is located in 3.0\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "minima =15\n",
    "alpha = .01 #razon de aprendizaje\n",
    "presition = 0.0001\n",
    "move=1 #in this case any number > presition\n",
    "count =0\n",
    "while abs(move)> presition:\n",
    "    gradient = function_derivate(minima)\n",
    "    move = gradient * alpha\n",
    "    minima = minima-move\n",
    "    count += 1\n",
    "    #print(move)\n",
    "\n",
    "print(\"The minima is located in {}\" .format(round(minima,2)))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
